"""
å¹¶è¡ŒMD5éªŒè¯å™¨ - åŸºäºç°æœ‰ThreadPoolExecutoræ¨¡å¼ä¼˜åŒ–
"""
import asyncio
import hashlib
import os
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from PySide6.QtCore import QObject, Signal

from .models import FileItem, DownloadConfig, DownloadStatus, MD5VerifyStatus


@dataclass
class MD5Result:
    """MD5è®¡ç®—ç»“æœ"""
    filename: str
    success: bool
    md5_hash: str
    calculated_md5: str = ""
    file_size: int = 0
    elapsed_time: float = 0.0
    error: str = ""


class ParallelMD5Calculator(QObject):
    """å¹¶è¡ŒMD5éªŒè¯å™¨ - ä¸“ä¸ºæµ·é‡å°æ–‡ä»¶ä¼˜åŒ–"""
    
    # ä¿¡å·å®šä¹‰ - ä¸ç°æœ‰UIå…¼å®¹
    progress_updated = Signal(str, float)  # æ–‡ä»¶å, è¿›åº¦
    file_completed = Signal(str, bool, str)  # æ–‡ä»¶å, æˆåŠŸ, æ¶ˆæ¯  
    overall_progress = Signal(float, int, int)  # è¿›åº¦%, å®Œæˆæ•°, æ€»æ•°
    log_message = Signal(str)  # æ—¥å¿—æ¶ˆæ¯
    
    def __init__(self, config: Optional[DownloadConfig] = None):
        super().__init__()
        self.config = config or DownloadConfig()
        self._cancelled = False
        
    async def calculate_md5_parallel(self, file_items: List[FileItem], 
                                   output_dir: Path) -> Dict[str, MD5Result]:
        """å¹¶è¡Œè®¡ç®—MD5 - å¤ç”¨ç°æœ‰ThreadPoolExecutoræ¨¡å¼"""
        if not file_items:
            return {}
        
        self._cancelled = False
        results = {}
        
        # ä½¿ç”¨ç°æœ‰çš„æ™ºèƒ½å¹¶å‘ç®—æ³•
        optimal_threads = self._get_optimal_threads(file_items)
        batch_size = self._get_optimal_batch_size(file_items)
        
        self.log_message.emit(f"ğŸš€ å¯åŠ¨å¹¶è¡ŒMD5è®¡ç®—: {len(file_items)} ä¸ªæ–‡ä»¶")
        self.log_message.emit(f"âš¡ ä½¿ç”¨ {optimal_threads} çº¿ç¨‹, æ‰¹æ¬¡å¤§å° {batch_size}")
        
        # åˆ†æ‰¹å¤„ç† - å¤ç”¨ç°æœ‰åˆ†æ‰¹é€»è¾‘
        batches = self._create_batches(file_items, batch_size)
        completed_files = 0
        total_files = len(file_items)
        
        for batch_idx, batch in enumerate(batches):
            if self._cancelled:
                break
                
            self.log_message.emit(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} ({len(batch)} ä¸ªæ–‡ä»¶)")
            
            # å¹¶è¡Œå¤„ç†å½“å‰æ‰¹æ¬¡ - å¤ç”¨ç°æœ‰ThreadPoolExecutoræ¨¡å¼
            batch_results = await self._process_batch_parallel(
                batch, output_dir, optimal_threads
            )
            
            # å¤„ç†æ‰¹æ¬¡ç»“æœ
            for result in batch_results:
                results[result.filename] = result
                completed_files += 1
                
                # å‘é€æ–‡ä»¶å®Œæˆä¿¡å·
                success_msg = "MD5éªŒè¯æˆåŠŸ" if result.success and not result.error else result.error
                self.file_completed.emit(result.filename, result.success, success_msg)
                
                # æ›´æ–°æ•´ä½“è¿›åº¦
                progress = (completed_files / total_files) * 100
                self.overall_progress.emit(progress, completed_files, total_files)
            
            # æ‰¹æ¬¡é—´æš‚åœï¼Œä¿æŒUIå“åº”
            await asyncio.sleep(0.01)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        if not self._cancelled:
            self._log_performance_stats(results)
        
        return results
    
    async def _process_batch_parallel(self, batch: List[FileItem], 
                                    output_dir: Path, max_workers: int) -> List[MD5Result]:
        """å¹¶è¡Œå¤„ç†æ‰¹æ¬¡ - å¤ç”¨ç°æœ‰ThreadPoolExecutoræ¨¡å¼"""
        loop = asyncio.get_event_loop()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            tasks = [
                loop.run_in_executor(executor, self._calculate_single_md5, item, output_dir)
                for item in batch
            ]
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ”¯æŒå–æ¶ˆ
            batch_results = []
            completed_tasks = 0
            
            for task in asyncio.as_completed(tasks):
                if self._cancelled:
                    # å–æ¶ˆå‰©ä½™ä»»åŠ¡
                    for remaining_task in tasks:
                        if not remaining_task.done():
                            remaining_task.cancel()
                    break
                
                try:
                    result = await task
                    batch_results.append(result)
                    completed_tasks += 1
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶é¡¹
                    corresponding_item = None
                    for item in batch:
                        if not any(r.filename == item.filename for r in batch_results):
                            corresponding_item = item
                            break
                    
                    error_result = MD5Result(
                        filename=corresponding_item.filename if corresponding_item else "unknown",
                        success=False,
                        md5_hash=corresponding_item.md5 if corresponding_item else "",
                        error=f"è®¡ç®—å¼‚å¸¸: {str(e)}"
                    )
                    batch_results.append(error_result)
                    completed_tasks += 1
            
            return batch_results
    
    def _calculate_single_md5(self, file_item: FileItem, output_dir: Path) -> MD5Result:
        """è®¡ç®—å•ä¸ªæ–‡ä»¶çš„MD5 - ä¼˜åŒ–ç‰ˆæœ¬"""
        start_time = time.time()
        file_path = output_dir / file_item.full_filename
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                return MD5Result(
                    filename=file_item.filename,
                    success=False,
                    md5_hash=file_item.md5,
                    error="æ–‡ä»¶ä¸å­˜åœ¨"
                )
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = file_path.stat().st_size
            
            # è¯»å–å¹¶è®¡ç®—MD5
            calculated_md5 = self._calculate_file_md5(file_path)
            
            # éªŒè¯MD5
            expected_md5 = file_item.md5.lower()
            actual_md5 = calculated_md5.lower()
            is_match = expected_md5 == actual_md5
            
            elapsed_time = time.time() - start_time
            
            return MD5Result(
                filename=file_item.filename,
                success=True,
                md5_hash=expected_md5,
                calculated_md5=actual_md5,
                file_size=file_size,
                elapsed_time=elapsed_time,
                error="" if is_match else f"MD5ä¸åŒ¹é…: æœŸæœ›{expected_md5}, å®é™…{actual_md5}"
            )
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            return MD5Result(
                filename=file_item.filename,
                success=False,
                md5_hash=file_item.md5,
                elapsed_time=elapsed_time,
                error=f"è®¡ç®—MD5å¤±è´¥: {str(e)}"
            )
    
    def _calculate_file_md5(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶MD5 - Apple Siliconä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            # å°è¯•ä½¿ç”¨Apple Siliconä¼˜åŒ–
            return self._calculate_md5_apple_optimized(file_path)
        except Exception as e:
            raise Exception(f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _calculate_md5_apple_optimized(self, file_path: Path) -> str:
        """Apple Siliconä¼˜åŒ–çš„MD5è®¡ç®—"""
        import platform
        
        # æ£€æµ‹Apple Silicon
        is_apple_silicon = (platform.system() == "Darwin" and 
                           platform.machine() == "arm64")
        
        try:
            file_size = file_path.stat().st_size
            
            if is_apple_silicon:
                # Apple Siliconä¼˜åŒ–è·¯å¾„
                if file_size < 512 * 1024:  # <512KBå°æ–‡ä»¶
                    # ç»Ÿä¸€å†…å­˜æ¶æ„ä¼˜åŠ¿ï¼šä¸€æ¬¡æ€§è¯»å–
                    with open(file_path, 'rb') as f:
                        data = f.read()
                    
                    # å°è¯•ç¡¬ä»¶åŠ é€Ÿæ¨¡å¼
                    try:
                        return hashlib.md5(data, usedforsecurity=False).hexdigest()
                    except TypeError:
                        return hashlib.md5(data).hexdigest()
                else:
                    # ä½¿ç”¨Apple Siliconä¼˜åŒ–çš„16KBå—å¤§å°
                    md5_hash = hashlib.md5()
                    with open(file_path, 'rb') as f:
                        while chunk := f.read(16384):  # 16KB - Apple Siliconæœ€ä¼˜
                            if self._cancelled:
                                break
                            md5_hash.update(chunk)
                    return md5_hash.hexdigest()
            else:
                # éApple Siliconï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
                md5_hash = hashlib.md5()
                
                if file_size < 1024 * 1024:  # <1MB
                    with open(file_path, 'rb') as f:
                        md5_hash.update(f.read())
                else:
                    # 64KBå—
                    with open(file_path, 'rb') as f:
                        while chunk := f.read(65536):
                            if self._cancelled:
                                break
                            md5_hash.update(chunk)
                
                return md5_hash.hexdigest()
                
        except Exception as e:
            raise Exception(f"MD5è®¡ç®—å¤±è´¥: {str(e)}")
    
    def _get_optimal_threads(self, file_items: List[FileItem]) -> int:
        """è·å–æœ€ä¼˜çº¿ç¨‹æ•° - å¤ç”¨ç°æœ‰ç®—æ³•"""
        # åŸºäºCPUæ ¸å¿ƒæ•°å’Œæ–‡ä»¶ç‰¹å¾
        cpu_cores = os.cpu_count() or 4
        
        # é’ˆå¯¹æµ·é‡å°æ–‡ä»¶ä¼˜åŒ–
        base_threads = min(cpu_cores * 4, 32)  # æœ€å¤š32çº¿ç¨‹
        
        # æ ¹æ®æ–‡ä»¶æ•°é‡è°ƒæ•´
        file_count = len(file_items)
        if file_count < 10:
            return min(file_count, 4)
        elif file_count < 100:
            return min(base_threads // 2, 16)
        else:
            return base_threads
    
    def _get_optimal_batch_size(self, file_items: List[FileItem]) -> int:
        """è·å–æœ€ä¼˜æ‰¹æ¬¡å¤§å° - åŸºäºåŒé‡æ€§èƒ½æµ‹è¯•ä¼˜åŒ–"""
        file_count = len(file_items)
        
        # åŸºäºä¸åŒè§„æ¨¡çš„æ€§èƒ½æµ‹è¯•ç»“æœä¼˜åŒ–
        if file_count < 20:
            return min(file_count, 10)  # æå°æ•°é‡ï¼šé¿å…ç©ºæ‰¹æ¬¡
        elif file_count < 200:
            # å°è§„æ¨¡ï¼šå¤§æ‰¹æ¬¡å‡å°‘è°ƒåº¦å¼€é”€ï¼ŒI/Oç«äº‰ä¸æ¿€çƒˆ
            return min(50, file_count)  
        elif file_count < 1000:
            # ä¸­è§„æ¨¡ï¼šå¹³è¡¡è°ƒåº¦å¼€é”€å’ŒI/Oç«äº‰
            return 30
        elif file_count < 5000:
            # å¤§è§„æ¨¡ï¼šI/Oç«äº‰å¼€å§‹æ˜¾ç°ï¼Œå°æ‰¹æ¬¡æ›´ä¼˜
            return 20  
        else:
            # æµ·é‡æ–‡ä»¶ï¼šä¸¥é‡I/Oç«äº‰ï¼Œæœ€å°æ‰¹æ¬¡é¿å…ç£ç›˜äº‰æŠ¢
            return 15
    
    def _create_batches(self, file_items: List[FileItem], batch_size: int) -> List[List[FileItem]]:
        """åˆ›å»ºæ‰¹æ¬¡ - ç®€åŒ–ç‰ˆæœ¬"""
        batches = []
        for i in range(0, len(file_items), batch_size):
            batches.append(file_items[i:i + batch_size])
        return batches
    
    def _log_performance_stats(self, results: Dict[str, MD5Result]):
        """è®°å½•æ€§èƒ½ç»Ÿè®¡"""
        successful_results = [r for r in results.values() if r.success]
        failed_results = [r for r in results.values() if not r.success]
        
        success_count = len(successful_results)
        failed_count = len(failed_results)
        
        self.log_message.emit(f"âœ… å¹¶è¡ŒMD5è®¡ç®—å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
        
        if successful_results:
            total_size = sum(r.file_size for r in successful_results)
            total_time = sum(r.elapsed_time for r in successful_results)
            
            if total_time > 0:
                throughput_mbs = (total_size / 1024 / 1024) / total_time
                files_per_sec = len(successful_results) / total_time
                
                self.log_message.emit(f"ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡: {throughput_mbs:.1f} MB/s, {files_per_sec:.1f} æ–‡ä»¶/ç§’")
                self.log_message.emit(f"ğŸ’¾ å¤„ç†æ•°æ®: {total_size/1024/1024:.1f} MB, è€—æ—¶ {total_time:.1f} ç§’")
    
    def cancel_calculation(self):
        """å–æ¶ˆè®¡ç®—"""
        self._cancelled = True
        self.log_message.emit("âš ï¸ MD5è®¡ç®—å·²å–æ¶ˆ") 
#!/usr/bin/env python3
"""
DLC Manager ç¬¬ä¸‰é˜¶æ®µå‹ç¼©ä¼ è¾“ä¼˜åŒ–æµ‹è¯•
éªŒè¯JSONå‹ç¼©ä¼˜åŒ–ã€PNGæµå¼ä¼ è¾“ã€æ™ºèƒ½æ–‡ä»¶åˆ†æå’Œæ€§èƒ½ç»Ÿè®¡
"""
import sys
import asyncio
import time
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core import (
    CompressionManager, CompressionConfig, FileTypeAnalyzer,
    DownloadConfig, FileItem, Downloader
)


def test_file_type_analyzer():
    """æµ‹è¯•æ–‡ä»¶ç±»å‹åˆ†æå™¨"""
    print("\n" + "="*80)
    print("æ–‡ä»¶ç±»å‹åˆ†æå™¨æµ‹è¯•")
    print("="*80)
    
    # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        FileItem(filename="small_song.json", md5="abc123", size=50*1024),      # 50KB JSON
        FileItem(filename="large_song.json", md5="def456", size=500*1024),     # 500KB JSON
        FileItem(filename="cover_small.png", md5="ghi789", size=200*1024),     # 200KB PNG
        FileItem(filename="cover_medium.png", md5="jkl012", size=1*1024*1024), # 1MB PNG
        FileItem(filename="cover_large.png", md5="mno345", size=5*1024*1024),  # 5MB PNG
        FileItem(filename="unknown.txt", md5="pqr678", size=100*1024),         # 100KB TXT
    ]
    
    print(f"{'æ–‡ä»¶å':<25} {'å¤§å°':<15} {'åˆ†ç±»':<15} {'åº”å‹ç¼©':<10} {'åº”æµå¼':<10}")
    print("-" * 80)
    
    for file_item in test_files:
        category = FileTypeAnalyzer.categorize_file(file_item)
        should_compress = FileTypeAnalyzer.should_compress(file_item, CompressionConfig())
        
        # åˆ›å»ºä¸´æ—¶ç®¡ç†å™¨æµ‹è¯•æµå¼åˆ¤æ–­
        temp_manager = CompressionManager()
        should_stream = temp_manager.streaming.should_use_streaming(file_item)
        
        size_str = f"{file_item.size/1024:.0f}KB" if file_item.size < 1024*1024 else f"{file_item.size/1024/1024:.1f}MB"
        
        print(f"{file_item.filename:<25} {size_str:<15} {category.value:<15} {'æ˜¯' if should_compress else 'å¦':<10} {'æ˜¯' if should_stream else 'å¦':<10}")
    
    print("\nâœ… æ–‡ä»¶ç±»å‹åˆ†æå™¨æµ‹è¯•å®Œæˆ")
    return True


def test_compression_config_integration():
    """æµ‹è¯•å‹ç¼©é…ç½®é›†æˆ"""
    print("\n" + "="*80)
    print("å‹ç¼©é…ç½®é›†æˆæµ‹è¯•")
    print("="*80)
    
    # æµ‹è¯•DownloadConfigåˆ›å»ºCompressionConfig
    download_config = DownloadConfig(
        force_json_compression=True,
        enable_png_streaming=True,
        compression_performance_tracking=True,
        use_http2=True
    )
    
    compression_config = download_config.create_compression_config()
    
    print("DownloadConfig â†’ CompressionConfig æ˜ å°„:")
    print(f"  JSONå‹ç¼©: {compression_config.force_json_compression}")
    print(f"  PNGæµå¼: {compression_config.enable_png_optimization}")
    print(f"  æ€§èƒ½è·Ÿè¸ª: {compression_config.enable_performance_tracking}")
    print(f"  å‹ç¼©çº§åˆ«: {compression_config.compression_level} (HTTP/2: {download_config.use_http2})")
    print(f"  å—å¤§å°: {compression_config.stream_chunk_size/1024:.0f}KB")
    
    print("\nâœ… å‹ç¼©é…ç½®é›†æˆæµ‹è¯•å®Œæˆ")
    return True


def test_compression_manager_analysis():
    """æµ‹è¯•å‹ç¼©ç®¡ç†å™¨æ–‡ä»¶åˆ†æ"""
    print("\n" + "="*80)
    print("å‹ç¼©ç®¡ç†å™¨æ–‡ä»¶åˆ†ææµ‹è¯•")
    print("="*80)
    
    manager = CompressionManager()
    
    # æµ‹è¯•ä¸åŒç±»å‹æ–‡ä»¶çš„åˆ†æç»“æœ
    test_cases = [
        FileItem(filename="song1.json", md5="test1", size=600*1024),     # 600KB JSON
        FileItem(filename="cover1.png", md5="test2", size=1.5*1024*1024), # 1.5MB PNG
        FileItem(filename="tiny.json", md5="test3", size=10*1024),       # 10KB JSON
        FileItem(filename="huge.png", md5="test4", size=8*1024*1024),    # 8MB PNG
    ]
    
    print(f"{'æ–‡ä»¶å':<20} {'ç±»åˆ«':<15} {'å‹ç¼©å»ºè®®':<10} {'æµå¼å»ºè®®':<10} {'é¢„è®¡èŠ‚çœ':<15} {'ä¼˜åŒ–æ–¹æ³•':<15}")
    print("-" * 100)
    
    for file_item in test_cases:
        analysis = manager.analyze_file_requirements(file_item)
        
        should_compress = "æ˜¯" if analysis['should_compress'] else "å¦"
        should_stream = "æ˜¯" if analysis['should_stream'] else "å¦"
        estimated_savings = f"{analysis['estimated_savings']['estimated_savings_percent']:.0f}%"
        method = analysis['estimated_savings']['method']
        
        print(f"{file_item.filename:<20} {analysis['category']:<15} {should_compress:<10} {should_stream:<10} {estimated_savings:<15} {method:<15}")
        
        # æµ‹è¯•è¯·æ±‚å¤´ç”Ÿæˆ
        headers = analysis['optimal_headers']
        if headers:
            print(f"  ğŸ“‹ è¯·æ±‚å¤´: {headers}")
    
    print("\nâœ… å‹ç¼©ç®¡ç†å™¨åˆ†ææµ‹è¯•å®Œæˆ")
    return True


async def test_compression_processing():
    """æµ‹è¯•å‹ç¼©æ•°æ®å¤„ç†"""
    print("\n" + "="*80)
    print("å‹ç¼©æ•°æ®å¤„ç†æµ‹è¯•")
    print("="*80)
    
    import gzip
    import json
    
    manager = CompressionManager()
    
    # åˆ›å»ºæµ‹è¯•JSONæ•°æ®
    test_json_data = {
        "song_title": "Test Song",
        "artist": "Test Artist",
        "duration": 180,
        "lyrics": ["Line 1", "Line 2", "Line 3"] * 100,  # é‡å¤æ•°æ®ï¼Œåˆ©äºå‹ç¼©
        "metadata": {
            "key": "value",
            "nested": {"deep": "data"}
        }
    }
    
    # åŸå§‹JSONå­—ç¬¦ä¸²
    original_json = json.dumps(test_json_data, indent=2)
    original_bytes = original_json.encode('utf-8')
    original_size = len(original_bytes)
    
    # ä½¿ç”¨gzipå‹ç¼©
    compressed_bytes = gzip.compress(original_bytes)
    compressed_size = len(compressed_bytes)
    
    print(f"æµ‹è¯•æ•°æ®:")
    print(f"  åŸå§‹å¤§å°: {original_size/1024:.1f}KB")
    print(f"  å‹ç¼©å¤§å°: {compressed_size/1024:.1f}KB")
    print(f"  å‹ç¼©æ¯”: {compressed_size/original_size:.2%}")
    print(f"  èŠ‚çœ: {(1-compressed_size/original_size)*100:.1f}%")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ–‡ä»¶é¡¹
    file_item = FileItem(filename="test_song.json", md5="test", size=original_size)
    
    # è®°å½•å¤„ç†æ¶ˆæ¯
    messages = []
    def progress_callback(msg):
        messages.append(msg)
        print(f"  ğŸ“ {msg}")
    
    # æµ‹è¯•å‹ç¼©æ•°æ®å¤„ç†
    start_time = time.time()
    processed_data = await manager.process_response_data(
        compressed_bytes, 'gzip', file_item, progress_callback
    )
    process_time = time.time() - start_time
    
    # éªŒè¯è§£å‹ç¼©ç»“æœ
    processed_json = processed_data.decode('utf-8')
    processed_data_obj = json.loads(processed_json)
    
    success = processed_data_obj == test_json_data
    
    print(f"\nè§£å‹ç¼©ç»“æœ:")
    print(f"  å¤„ç†æ—¶é—´: {process_time*1000:.1f}ms")
    print(f"  æ•°æ®å®Œæ•´æ€§: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")
    print(f"  å¤„ç†æ¶ˆæ¯æ•°: {len(messages)}")
    
    # æµ‹è¯•å‹ç¼©ç»Ÿè®¡
    compression_summary = manager.get_session_summary()
    stats = compression_summary['compression_stats']
    
    print(f"\nå‹ç¼©ç»Ÿè®¡:")
    print(f"  å¤„ç†æ–‡ä»¶æ•°: {stats['files_processed']}")
    print(f"  æ€»ä½“å‹ç¼©æ¯”: {stats['overall_compression_ratio']:.2%}")
    print(f"  æ€»ä½“èŠ‚çœ: {stats['overall_savings_percent']:.1f}%")
    print(f"  èŠ‚çœå¤§å°: {stats['overall_savings_mb']:.3f}MB")
    
    print("\nâœ… å‹ç¼©æ•°æ®å¤„ç†æµ‹è¯•å®Œæˆ")
    return success


def test_downloader_integration():
    """æµ‹è¯•ä¸‹è½½å™¨é›†æˆ"""
    print("\n" + "="*80)
    print("ä¸‹è½½å™¨é›†æˆæµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºå¯ç”¨å‹ç¼©ä¼˜åŒ–çš„é…ç½®
    config = DownloadConfig(
        enable_compression_optimization=True,
        force_json_compression=True,
        enable_png_streaming=True,
        compression_performance_tracking=True
    )
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = Downloader(config)
    
    print("ä¸‹è½½å™¨å‹ç¼©ä¼˜åŒ–é›†æˆçŠ¶æ€:")
    print(f"  å‹ç¼©ç®¡ç†å™¨: {'âœ… å·²åˆ›å»º' if downloader.compression_manager else 'âŒ æœªåˆ›å»º'}")
    
    if downloader.compression_manager:
        print(f"  JSONå‹ç¼©: {'âœ… å¯ç”¨' if config.force_json_compression else 'âŒ ç¦ç”¨'}")
        print(f"  PNGæµå¼: {'âœ… å¯ç”¨' if config.enable_png_streaming else 'âŒ ç¦ç”¨'}")
        print(f"  æ€§èƒ½è·Ÿè¸ª: {'âœ… å¯ç”¨' if config.compression_performance_tracking else 'âŒ ç¦ç”¨'}")
        
        # æµ‹è¯•é…ç½®ä¼ é€’
        compression_config = downloader.compression_manager.config
        print(f"  é…ç½®ä¼ é€’: å‹ç¼©çº§åˆ«={compression_config.compression_level}, å—å¤§å°={compression_config.stream_chunk_size/1024:.0f}KB")
    
    # æµ‹è¯•ç¦ç”¨å‹ç¼©ä¼˜åŒ–çš„æƒ…å†µ
    config_disabled = DownloadConfig(enable_compression_optimization=False)
    downloader_disabled = Downloader(config_disabled)
    
    print(f"\nç¦ç”¨å‹ç¼©ä¼˜åŒ–:")
    print(f"  å‹ç¼©ç®¡ç†å™¨: {'âœ… å·²åˆ›å»º' if downloader_disabled.compression_manager else 'âŒ æœªåˆ›å»º'}")
    
    print("\nâœ… ä¸‹è½½å™¨é›†æˆæµ‹è¯•å®Œæˆ")
    return True


def test_performance_estimation():
    """æµ‹è¯•æ€§èƒ½é¢„ä¼°"""
    print("\n" + "="*80)
    print("æ€§èƒ½é¢„ä¼°æµ‹è¯•")
    print("="*80)
    
    manager = CompressionManager()
    
    # æ¨¡æ‹ŸçœŸå®çš„DLCæ–‡ä»¶åˆ†å¸ƒ
    test_scenarios = [
        {
            "name": "å…¸å‹JSONæ­Œæ›²æ–‡ä»¶",
            "files": [
                FileItem(filename=f"song_{i}.json", md5=f"hash{i}", size=600*1024)  # 600KB JSON
                for i in range(100)
            ]
        },
        {
            "name": "å…¸å‹PNGå°é¢æ–‡ä»¶", 
            "files": [
                FileItem(filename=f"cover_{i}.png", md5=f"hash{i}", size=1.2*1024*1024)  # 1.2MB PNG
                for i in range(50)
            ]
        },
        {
            "name": "æ··åˆæ–‡ä»¶åœºæ™¯",
            "files": (
                [FileItem(filename=f"song_{i}.json", md5=f"hash{i}", size=600*1024) for i in range(70)] +
                [FileItem(filename=f"cover_{i}.png", md5=f"hash{i}", size=1.2*1024*1024) for i in range(30)]
            )
        }
    ]
    
    print(f"{'åœºæ™¯':<20} {'æ–‡ä»¶æ•°':<8} {'æ€»å¤§å°':<15} {'é¢„è®¡èŠ‚çœ':<15} {'èŠ‚çœç™¾åˆ†æ¯”':<12} {'ä¸»è¦ä¼˜åŒ–':<20}")
    print("-" * 100)
    
    for scenario in test_scenarios:
        files = scenario["files"]
        total_size = sum(f.size for f in files)
        total_savings = 0
        compression_files = 0
        streaming_files = 0
        
        for file_item in files:
            analysis = manager.analyze_file_requirements(file_item)
            estimated_savings = analysis['estimated_savings']['estimated_savings_bytes']
            total_savings += estimated_savings
            
            if analysis['should_compress']:
                compression_files += 1
            if analysis['should_stream']:
                streaming_files += 1
        
        savings_percent = (total_savings / total_size) * 100 if total_size > 0 else 0
        total_size_mb = total_size / (1024 * 1024)
        total_savings_mb = total_savings / (1024 * 1024)
        
        optimization_desc = []
        if compression_files > 0:
            optimization_desc.append(f"{compression_files}ä¸ªå‹ç¼©")
        if streaming_files > 0:
            optimization_desc.append(f"{streaming_files}ä¸ªæµå¼")
        
        optimization_str = ", ".join(optimization_desc) if optimization_desc else "æ— ä¼˜åŒ–"
        
        print(f"{scenario['name']:<20} {len(files):<8} {total_size_mb:.1f}MB{'':<6} {total_savings_mb:.1f}MB{'':<6} {savings_percent:.1f}%{'':<7} {optimization_str:<20}")
    
    print("\nç†è®ºæ€§èƒ½æå‡:")
    print("ğŸ“ˆ JSONæ–‡ä»¶gzipå‹ç¼©: èŠ‚çœ75%ä¼ è¾“é‡ï¼Œå‡å°‘ä¸‹è½½æ—¶é—´")
    print("ğŸ“ˆ PNGæµå¼ä¼ è¾“: å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œé¿å…å¤§æ–‡ä»¶é˜»å¡")
    print("ğŸ“ˆ æ™ºèƒ½æ–‡ä»¶åˆ†æ: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ä¼ è¾“ç­–ç•¥")
    print("ğŸ“ˆ HTTP/2 + å‹ç¼©: å¤šè·¯å¤ç”¨ + å‹ç¼©ä¼ è¾“ï¼Œç»¼åˆæå‡30-50%")
    
    print("\nâœ… æ€§èƒ½é¢„ä¼°æµ‹è¯•å®Œæˆ")
    return True


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ DLC Manager ç¬¬ä¸‰é˜¶æ®µå‹ç¼©ä¼ è¾“ä¼˜åŒ–æµ‹è¯•")
    print("="*80)
    
    start_time = time.time()
    
    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        tests = [
            ("æ–‡ä»¶ç±»å‹åˆ†æå™¨", test_file_type_analyzer),
            ("å‹ç¼©é…ç½®é›†æˆ", test_compression_config_integration),
            ("å‹ç¼©ç®¡ç†å™¨åˆ†æ", test_compression_manager_analysis),
            ("å‹ç¼©æ•°æ®å¤„ç†", test_compression_processing),
            ("ä¸‹è½½å™¨é›†æˆ", test_downloader_integration),
            ("æ€§èƒ½é¢„ä¼°", test_performance_estimation),
        ]
        
        results = {}
        for test_name, test_func in tests:
            print(f"\nğŸ§ª æ‰§è¡Œæµ‹è¯•: {test_name}")
            try:
                if asyncio.iscoroutinefunction(test_func):
                    result = await test_func()
                else:
                    result = test_func()
                results[test_name] = result
                print(f"âœ… {test_name}: {'é€šè¿‡' if result else 'å¤±è´¥'}")
            except Exception as e:
                results[test_name] = False
                print(f"âŒ {test_name}: å¼‚å¸¸ - {str(e)}")
        
        # æ±‡æ€»ç»“æœ
        elapsed = time.time() - start_time
        passed = sum(results.values())
        total = len(results)
        
        print(f"\n" + "="*80)
        print("ğŸ“Š ç¬¬ä¸‰é˜¶æ®µå‹ç¼©ä¼˜åŒ–æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*80)
        
        for test_name, success in results.items():
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"   {test_name}: {status}")
        
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} é€šè¿‡")
        print(f"â±ï¸  æ€»æµ‹è¯•æ—¶é—´: {elapsed:.2f}ç§’")
        
        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰ç¬¬ä¸‰é˜¶æ®µå‹ç¼©ä¼˜åŒ–æµ‹è¯•é€šè¿‡ï¼")
            print("\nğŸ’¡ ç¬¬ä¸‰é˜¶æ®µä¼˜åŒ–æ•ˆæœé¢„æœŸ:")
            print("   ğŸ“¦ JSONæ–‡ä»¶ä¼ è¾“é‡å‡å°‘70%+")
            print("   ğŸ–¼ï¸  PNGå¤§æ–‡ä»¶å†…å­˜å‹å¥½å¤„ç†")
            print("   ğŸš€ HTTP/2 + å‹ç¼©ç»„åˆä¼˜åŒ–30-50%æ€§èƒ½æå‡")
            print("   ğŸ“Š è¯¦ç»†çš„å‹ç¼©æ•ˆæœç»Ÿè®¡å’Œç›‘æ§")
            print("\nğŸš€ å¯ä»¥å¼€å§‹å®é™…ä¸‹è½½æµ‹è¯•!")
            return 0
        else:
            print("âŒ éƒ¨åˆ†ç¬¬ä¸‰é˜¶æ®µæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
            return 1
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    print("ğŸ“¦ æ£€æŸ¥ç¬¬ä¸‰é˜¶æ®µä¾èµ–...")
    
    missing_deps = []
    try:
        import gzip
        print("   âœ… gzip æ¨¡å—å¯ç”¨")
    except ImportError:
        missing_deps.append("gzip")
    
    try:
        import zlib
        print("   âœ… zlib æ¨¡å—å¯ç”¨")
    except ImportError:
        missing_deps.append("zlib")
    
    try:
        import aiofiles
        print("   âœ… aiofiles æ¨¡å—å¯ç”¨")
    except ImportError:
        missing_deps.append("aiofiles")
    
    try:
        # å¯é€‰ä¾èµ–
        import brotli
        print("   âœ… brotli æ¨¡å—å¯ç”¨ (å¯é€‰)")
    except ImportError:
        print("   âš ï¸  brotli æ¨¡å—ä¸å¯ç”¨ (å¯é€‰ï¼Œç”¨äºBrotliå‹ç¼©)")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘å¿…éœ€ä¾èµ–: {', '.join(missing_deps)}")
        sys.exit(1)
    
    print()
    sys.exit(asyncio.run(main())) 